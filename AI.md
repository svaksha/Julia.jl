**Machine learning and statistics are closely related fields, so do check out the [Statistics](https://github.com/svaksha/Julia.jl/blob/master/Statistics.md) page for more packages. Category sorting of packages is a WIP.**

+ [MACHINE LEARNING](#machine-learning)
+ [NLP](#nlp)
   + [English](#english)
   + [Finite Automata](#finite-automata)
   + [Japanese](#japanese)
+ [REINFORCEMENT LEARNING](#reinforcement-learning)
+ [SPEECH RECOGNITION](#speech-recognition)
+ [SUPERVISED LEARNING](#supervised-learning)
+ [UNSUPERVISED LEARNING](#unsupervised-learning)
   + [Neural Networks](#neural-networks)

----


# MACHINE LEARNING
+ [BackpropNeuralNet.jl](https://github.com/compressed/BackpropNeuralNet.jl) :: A neural network in Julia.
+ [BayesianNonparametrics.jl](https://github.com/OFAI/BayesianNonparametrics.jl) :: Bayesian nonparametrics in Julia.
+ [BNMF.jl](https://github.com/r9y9/BNMF.jl) :: Gamma Process Non-negative Matrix Factorization (GaP-NMF).
+ [ConfidenceWeighted.jl](https://github.com/chezou/ConfidenceWeighted.jl) :: Confidence weighted, a machine learning algorithm.
+ [Contingency.jl](https://github.com/svs14/Contingency.jl) :: Assorted techniques for the purpose of enabling automated machine learning.
+ [Clustering.jl](https://github.com/johnmyleswhite/Clustering.jl) :: Basic functions for clustering data ==> k-means, dp-means, etc..
+ [DAI.jl](https://github.com/binarybana/DAI.jl) :: A julia binding to the C++ discrete approximate inference library for graphical models: libDAI.
+ [DecisionTree.jl](https://github.com/bensadeghi/DecisionTree.jl) :: Julia implementation of Decision Tree (CART) and Random Forest algorithms.
+ [DecisionTrees.jl](https://github.com/MikeInnes/DecisionTrees.jl) :: {NotSupported}
+ [Discretizers.jl](https://github.com/sisl/Discretizers.jl) :: A package to support discretization methods and mapping functions for data discretization and label maps.
+ [EGR.jl](https://github.com/stefanks/EGR.jl) :: The Stochastic Gradient (SG) algorithm for machine learning.
+ [ELM.jl](https://github.com/lepisma/ELM.jl) :: Extreme Learning Machines are a variant of Single-Hidden Layer Feedforward Networks (SLFNs) with a significant departure as their weights aren't iteratively tuned. This boosts the speed of neurals nets heavily.
+ [EmpiricalRiskMinimization.jl](https://github.com/reesepathak/EmpiricalRiskMinimization.jl) :: Empirical Risk Minimization (and modeling) in Julia. 
+ [FeatureSelection.jl](https://github.com/Evizero/FeatureSelection.jl) :: Common measures and algorithms for feature selection.
+ [Flimsy.jl](https://github.com/thomlake/Flimsy.jl) :: Gradient based Machine Learning for Julia.
+ [FunctionalDataUtils.jl](https://github.com/rened/FunctionalDataUtils.jl) :: Utility functions for the FunctionalData package, mainly from the area of computer vision / machine learning.
+ [go.jl](https://github.com/dmrd/go.jl) :: A deep learning based Go bot implemented in Julia.
+ [GradientBoost.jl](https://github.com/svs14/GradientBoost.jl) :: Gradient boosting framework for Julia.
+ [Glmnet.jl](https://github.com/simonster/Glmnet.jl) :: Julia wrapper for fitting Lasso/ElasticNet GLM models using glmnet.
+ [HopfieldNets.jl](https://github.com/johnmyleswhite/HopfieldNets.jl) :: Discrete and continuous Hopfield networks in Julia.
+ [HSIC.jl](https://github.com/trappmartin/HSIC.jl) :: Julia implementations of the Hilbert-Schmidt Independence Criterion (HSIC).
+ [JuML.jl](https://github.com/Statfactory/JuML.jl) :: Machine Learning in Julia. 
+ [KaggleDigitRecognizer.jl](https://github.com/benhamner/KaggleDigitRecognizer.jl) :: Julia code for Kaggle's Digit Recognizer competition.
+ [KDTrees.jl](https://github.com/KristofferC/KDTrees.jl) :: KD Trees.
+ [Keras.jl](https://github.com/ayush1999/Keras.jl) :: A package built atop Flux to directly load Keras(.py) models into Flux.
+ [Kernels.jl](https://github.com/trthatcher/Kernels.jl) :: A Julia package for Mercer kernels and Gramian matrix calculation/approximation functions used in kernel methods of machine learning. 
+ [Knet.jl](https://github.com/denizyuret/Knet.jl) :: Koç University deep learning framework - A machine learning module implemented in Julia.
   * [KnetNLP](https://github.com/egeersu/KnetNLP) :: NLP models and utilities for Knet.
+ [kNN.jl](https://github.com/johnmyleswhite/kNN.jl) :: The k-Nearest Neighbors algorithm in Julia.
+ [KSVM.jl](https://github.com/remusao/KSVM.jl) by @remusao :: Kernel Support Vector Machine (SVM) written in Julia.
+ [KSVM.jl](https://github.com/Evizero/KSVM.jl) by @Evizero :: Support Vector Machines in pure Julia.
+ [Ladder.jl](https://github.com/mrtzh/Ladder.jl) :: A reliable leaderboard algorithm for machine learning competitions.
+ [Learn.jl](https://github.com/Rory-Finnegan/Learn.jl) :: Base framework library for machine learning packages.
+ [LearnBase.jl](https://github.com/Evizero/LearnBase.jl) :: Abstractions for Julia Machine Learning Packages.
+ [LearningStrategies.jl](https://github.com/JuliaML/LearningStrategies.jl) :: A generic and modular framework for building custom iterative algorithms in Julia. 
+ [liblinear.jl](https://github.com/tuzzeg/liblinear.jl) :: Liblinear binding to Julia.
+ [LIBSVM.jl](https://github.com/simonster/LIBSVM.jl) :: Julia bindings for LIBSVM.
+ [LossFunctions.jl](https://github.com/JuliaML/LossFunctions.jl) :: Julia package of loss functions for machine learning. Documentation: http://lossesjl.readthedocs.io/
+ [NMF.jl](https://github.com/lindahua/NMF.jl) :: A Julia package for non-negative matrix factorization (NMF).
+ [MachineLearning.jl](https://github.com/benhamner/MachineLearning.jl) :: is a Machine Learning library package that consolidates common machine learning algorithms written in pure Julia and presents a consistent API.
+ [Merlin.jl](https://github.com/hshindo/Merlin.jl) :: Flexible Deep Learning Framework in Julia.
+ [Mitosis.jl](https://github.com/mschauer/Mitosis.jl) :: Automatic probabilistic programming for scientific machine learning and dynamical models.
+ [MLDatasets.jl](https://github.com/JuliaML/MLDatasets.jl) :: Utility package for accessing common Machine Learning datasets in Julia.
+ [MLJ.jl](https://github.com/alan-turing-institute/MLJ.jl) :: MLJ (Machine Learning in Julia) is a toolbox written in Julia providing a common interface and meta-algorithms for selecting, tuning, evaluating, composing and comparing over 160 machine learning models written in Julia and other languages.
+ [MLLabelUtils.jl](https://github.com/JuliaML/MLLabelUtils.jl) :: Utility package for working with classification targets and label-encodings. Documentation: http://mllabelutilsjl.readthedocs.io/
+ [MLKernels.jl](https://github.com/trthatcher/MLKernels.jl) :: Mercer kernels and Gramian matrix calculation/approximation.
+ [MochaTheano.jl](https://github.com/benmoran/MochaTheano.jl) :: Allow use of Theano for automatic differentiation within Mocha, via PyCall.
+ [MXNet.jl](https://github.com/dmlc/MXNet.jl) :: Flexible and efficient deep learning in Julia.
+ [NetworkLearning.jl](https://github.com/zgornel/NetworkLearning.jl) :: Baseline collective classification library.
+ [Ollam.jl](https://github.com/mit-nlp/Ollam.jl) :: OLLAM = Online Learning of Linear Adaptatable Models.
+ [OnlineAI.jl](https://github.com/tbreloff/OnlineAI.jl) :: Machine learning for sequential/streaming data.  {Usable: 3, Robust: 3, Active: 3}
+ [Orchestra.jl](https://github.com/svs14/Orchestra.jl) :: Heterogeneous ensemble learning package for the Julia programming language.
+ [ParticleFilters.jl](https://github.com/JuliaPOMDP/ParticleFilters.jl) :: Simple particle filter implementation in Julia - works with `POMDPs.jl` models or others.
+ [PredictMD.jl](https://github.com/bcbi/PredictMD.jl) :: Uniform interface for machine learning in Julia.
+ [PrivateMultiplicativeWeights.jl](https://github.com/mrtzh/PrivateMultiplicativeWeights.jl) :: Differentially private synthetic data.
+ [ProjectiveDictionaryPairLearning.jl](https://github.com/quxiaofeng/ProjectiveDictionaryPairLearning.jl) :: Juia code for the paper S. Gu, L. Zhang, W. Zuo, and X. Feng, “Projective Dictionary Pair Learning for Pattern Classification,” In NIPS 2014.
+ [RegERMs.jl](https://github.com/BigCrunsh/RegERMs.jl) :: A package implementing several machine learning algorithms in a regularised empirical risk minimisation framework (SVMs, LogReg, Linear Regression) in Julia.
+ [SALSA.jl](https://github.com/jumutc/SALSA.jl) :: _S_oftware Lab for _A_dvanced Machine _L_earning and _S_tochastic _A_lgorithms is a native Julia implementation of the well known stochastic algorithms for linear and non-linear Support Vector Machines.
+ [ScikitLearn.jl](https://github.com/cstjean/ScikitLearn.jl) :: Julia implementation of the scikit-learn API.
    + Cheatsheet for [choosing the right estimator](http://scikit-learn.org/stable/tutorial/machine_learning_map/).
+ [ScikitLearnBase.jl](https://github.com/cstjean/ScikitLearnBase.jl) :: Definition of the [ScikitLearn.jl](https://github.com/cstjean/ScikitLearn.jl) API.
+ [SimpleML.jl](https://github.com/aviks/SimpleML.jl) :: Textbook implementations of some Machine Learning Algorithms in Julia.
+ [SFA.jl](https://github.com/makokal/SFA.jl) :: Implementation of the standard SFA (Slow Feature Analysis) algorithm (both linear and non-linear signal expansion) in Julia.
+ [SoftConfidenceWeighted.jl](https://github.com/IshitaTakeshi/SoftConfidenceWeighted.jl) :: Exact Soft Confidence-Weighted Learning.
+ [Strada.jl](https://github.com/pcmoritz/Strada.jl) :: A deep learning library for Julia based on Caffe.
+ [SVMLightLoader.jl](https://github.com/IshitaTakeshi/SVMLightLoader.jl) :: Loader of svmlight / liblinear format files.
+ [JuliaTakingFittingAPIsSeriously](https://github.com/JuliaTakingFittingAPIsSeriously) :: proof of concept taking the APIs for statistics, machine learning and other infomatics.
+ [TensorFlow.jl](https://github.com/malmaud/TensorFlow.jl) :: A Julia wrapper for TensorFlow, the open source machine learning framework from Google.
+ [TheDataMustFlow.jl](https://github.com/ExpandingMan/TheDataMustFlow.jl) :: Julia tools for feeding tabular data into machine learning. 
+ [TSVD.jl](https://github.com/andreasnoack/TSVD.jl) :: Truncated singular value decomposition with partial reorthogonalization.
+ [ValueHistories.jl](https://github.com/JuliaML/ValueHistories.jl) :: Utilities to efficiently track learning curves or other optimization information.
+ [XLATools.jl](https://github.com/MikeInnes/XLATools.jl) :: Provides access to XLA and the XRT runtime (in Tensorflow), including the ability to build and compile XLA computations using the IRTools format.


##### Resources
+ [DistLearn.jl](https://github.com/pluskid/DistLearn.jl) :: An example of distributed learning in Julia. Note: this is not a full featured distributed machine learning library, therefore we are not going to register this in the Julia package system.
+ [Examples from _Thoughtful Machine Learning_](https://github.com/thoughtfulml/examples).
+ [CIML](https://github.com/hal3/ciml) :: A Course in Machine Learning. This repository contains the source code for the CIML book (see http://ciml.info/) as well as any course materials that seem useful (slides, documents, labs, etc.).
+ [deepframeworks](https://github.com/zer0n/deepframeworks) :: An evaluation of Deep Learning Frameworks.
+ A [Machine Learning](http://work.caltech.edu/telecourse.html#lectures) course by Prof. Yaser Abu-Mostafa with videos on Youtube.
+ [Machine Learning Algorithm Cheat Sheet](http://www.lauradhamilton.com/machine-learning-algorithm-cheat-sheet) by Laura D Hamilton.
+ [machine-learning-cheat-sheet](https://github.com/soulmachine/machine-learning-cheat-sheet) :: Classical equations and diagrams in machine learning by @soulmachine.
+ [Machine Learning cheatsheet](http://eferm.com/machine-learning-cheat-sheet/).
+ [Big Data Machine Learning Patterns for Predictive Analytics](http://refcardz.dzone.com/refcardz/machine-learning-predictive) By Ricky Ho.
+ [juliastreetview](https://github.com/evq/juliastreetview) :: Updated sample code for the Kaggle Julia Street View Character Recognition Tutorial.
+ [ML4H.jl](https://github.com/johnmyleswhite/ML4H.jl) :: Machine Learning for Hackers in Julia.
+ [A curated list of awesome places to learn and/or practice algorithms](https://github.com/tayllan/awesome-algorithms).
+ A HN site for [ML](http://news.startup.ml/).


----

# NLP

+ [AdaGram.jl](https://github.com/sbos/AdaGram.jl) :: Adaptive Skip-gram implementation in Julia.
+ [Peter Norvig's spelling corrector ported to Julia](https://gist.github.com/kmsquire/7569843), is now a part of the [DataStructures.jl](https://github.com/JuliaLang/DataStructures.jl) package.
+ [allen](https://github.com/ninjin/allen) :: A syntacto-semantic natural language parser.
+ [BKTrees.jl](https://github.com/zgornel/BKTrees.jl) :: Julia implementation of Burkhard-Keller trees.
+ [ConceptnetNumberbatch.jl](https://github.com/zgornel/ConceptnetNumberbatch.jl) :: Julia interface to [ConceptnetNumberbatch](https://github.com/commonsense/conceptnet-numberbatch).
+ [CorpusLoaders.jl](https://github.com/JuliaText/CorpusLoaders.jl) :: A variety of loaders for various NLP corpora.
+ [DependencyTrees.jl](https://github.com/dellison/DependencyTrees.jl) :: A package for dependency parsing.
+ [DPL.jl](https://github.com/quxiaofeng/DPL.jl) :: Projective Dictionary Pair Learning - code for the paper S. Gu, L. Zhang, W. Zuo, and X. Feng, “Projective Dictionary Pair Learning for Pattern Classification,” In NIPS 20144. https://sites.google.com/site/shuhanggu/home
+ [GloVe.jl](https://github.com/domluna/GloVe.jl) :: Implements Global Word Vectors.
+ [Glowe.jl](https://github.com/zgornel/Glowe.jl) :: Julia interface to Global Word Vectors.
+ [GoodTuring.jl](https://github.com/JoFrhwld/GoodTuring.jl) :: A Julia implementation of Simple Good Turing smoothing, largely adapted from @maxbane.
+ [JuliaParser.jl](https://github.com/jakebolewski/JuliaParser.jl) :: A rewrite of Julia's parser in Julia.
+ [KUparser.jl](https://github.com/denizyuret/KUparser.jl) :: Dependency parsing with word vectors.
+ [Languages.jl](https://github.com/JuliaText/Languages.jl) :: A package for working with human languages.
+ [Levenshtein.jl](https://github.com/rawrgrr/Levenshtein.jl) :: Levenshtein distance between two strings.
+ [LTSV.jl](https://github.com/kshramt/LTSV.jl) :: Labeled Tab Separated Values (LTSV) parser.
+ [MeCab.jl](https://github.com/chezou/MeCab.jl) :: Julia binding of Japanese morphological analyzer MeCab.
+ [NGram.jl](https://github.com/remusao/NGram.jl) :: Implement the NGram model.
+ [ParserCombinator.jl](https://github.com/andrewcooke/ParserCombinator.jl) :: A parser combinator library.
+ [Parsimonious.jl](https://github.com/gitfoxi/Parsimonious.jl) :: A PEG parser generator.
+ [PEGParser.jl](https://github.com/abeschneider/PEGParser.jl) :: A PEG Parser for Julia with Packrat capabilties, inspired by pyparsing, parsimonious, boost::spirit, as well as several others.
+ [PyLexYacc.jl](https://github.com/iamed2/PyLexYacc.jl) :: An interface to Python Lex-Yacc package that uses reflection for most of its processing.
+ [SimpleParser.jl](https://github.com/ordovician/SimpleParser.jl) :: A very simple hackable parser and lexer for simple languages.
+ [Stemmers.jl](https://github.com/tanmaykm/Stemmers.jl) :: Interface for text stemmer implementations.
+ [StringAnalysis.jl](https://github.com/zgornel/StringAnalysis.jl) :: A hard fork of the [TextAnalysis.jl](https://github.com/JuliaText/TextAnalysis.jl) package, designed to provide a richer, faster and orthogonal API.
+ [Sumup.jl](https://github.com/remusao/Sumup.jl) :: Automatic multi-documents, multi-topics summarization based on topic extraction.
+ [Treekenize.jl](https://github.com/o-jasper/Treekenize.jl) :: Parser with beginners and enders and infix.
+ [Text.jl](https://github.com/mit-nlp/Text.jl) :: Numerous tools for text processing.
+ [TextAnalysis.jl](https://github.com/JuliaText/TextAnalysis.jl) :: A Julia package for text analysis.
+ [TopicModels.jl](https://github.com/slycoder/TopicModels.jl).
+ [TOML.jl](https://github.com/pygy/TOML.jl) :: A TOML parser.
+ [Word2Vec.jl](https://github.com/weijianzhang/Word2Vec.jl) :: Julia interface to word2vec.
+ [WordNet.jl](https://github.com/JuliaText/WordNet.jl) :: A Julia package for Princeton's WordNet®.

### English

+ [EnglishText.jl](https://github.com/TotalVerb/EnglishText.jl) :: Utilities for English-language quirks in Julia.
+ [Why.jl](https://github.com/TorkelE/Why.jl) :: A simple function, why, which gives randomly generated answers.

### [Finite Automata](https://en.wikipedia.org/wiki/Category:Finite_automata)

+ [FiniteStateMachine.jl](https://github.com/tinybike/FiniteStateMachine.jl) :: A simple Julia implementation of finite state machines.

### Japanese

+ [MeCab.jl](https://github.com/chezou/MeCab.jl) :: Julia binding of Japanese morphological analyzer MeCab.


----

# [REINFORCEMENT LEARNING](https://en.wikipedia.org/wiki/Reinforcement_learning)

+ [DeepQLearning.jl](https://github.com/Andy-P/DeepQLearning.jl) :: An implementation of DeepMind's Deep Q Learning algorithm described in _Playing Atari with Deep Reinforcement Learning_.
+ [Flux.jl](https://github.com/FluxML/Flux.jl) :: A library for machine learning implemented in Julia. Documentation: https://fluxml.ai/Flux.jl/stable/
   + [model-zoo](https://github.com/FluxML/model-zoo) :: A repository containing various demonstrations of the Flux machine learning library that can be freely used as a starting point for your own models.
+ [ReinforcementLearning.jl](https://github.com/jbrea/ReinforcementLearning.jl) by @jbrea :: A Reinforcement Learning package.
+ [ReinforcementLearning.jl](https://github.com/benhamner/ReinforcementLearning.jl) by @benhamner :: A Reinforcement Learning package.
+ [ReinforcementLearning.jl](https://github.com/JuliaReinforcementLearning/ReinforcementLearning.jl) by @JuliaReinforcementLearning :: A package for reinforcement learning research in Julia.
+ [TopoChains.jl](https://github.com/irhum/TopoChains.jl) :: A flexible data structure for multi-input multi-output model compositions of layers and functions. It provides a new data structure, a TopoChain, which was originally designed as the `Stack`, as part of Transformers.jl by Peter Cheng, and this has been repackaged here into a standalone package for general purpose use.
+ [Transformers.jl](https://github.com/chengchingwen/Transformers.jl) :: Julia Implementation of Transformer-based models, with `Flux.jl`.

----

# SPEECH RECOGNITION
+ [JuliaTorch](https://github.com/boathit/JuliaTorch) :: Using PyTorch in Julia Language via PyCall.
+ [MelGeneralizedCepstrums.jl](https://github.com/r9y9/MelGeneralizedCepstrums.jl) :: It provides a `mel generalized cepstrum` analysis for spectrum envelope estimation, which includes linear predicition, mel-cepstrum, generalized cepstrum and mel-generalized cepstrum analysis for Julia.
+ [MFCC.jl](https://github.com/JuliaDSP/MFCC.jl) :: Standard Mel Frequency Cepstral Coefficients feature extraction for speech analysis.
+ [SpeechBase.jl](https://github.com/r9y9/SpeechBase.jl).
+ [SPTK.jl](https://github.com/r9y9/SPTK.jl) :: A Julia wrapper for the Speech Signal Processing Toolkit (SPTK), based on the modified version of SPTK.
+ [SynthesisFilters.jl](https://github.com/r9y9/SynthesisFilters.jl) :: Speech Synthesis Filters.
+ [WORLD.jl](https://github.com/r9y9/WORLD.jl) :: A Julia wrapper for WORLD - a high-quality speech analysis, modification and synthesis system. WORLD provides a way to decompose a speech signal into: Fundamental frequency (F0), spectral envelope, excitation signal (or aperiodicy used in TANDEM-STRAIGHT), and re-synthesize a speech signal from these paramters. See here for the original WORLD.


----

# [SUPERVISED LEARNING](https://en.wikipedia.org/wiki/Supervised_learning)

+ [GURLS.jl](https://github.com/joehuchette/GURLS.jl) :: A pure Julia port of the GURLS supervised learning library.
+ [SupervisedLearning.jl](https://github.com/Evizero/SupervisedLearning.jl) :: Front-end interface for supervised machine learning.

##### Resources

+ [ml_cheat_sheet](https://github.com/rcompton/ml_cheat_sheet) :: Supervised learning superstitions cheat sheet.


----

# [UNSUPERVISED LEARNING](https://en.wikipedia.org/wiki/Unsupervised_learning)

+ [Mocha.jl](https://github.com/pluskid/Mocha.jl) :: A Deep Learning framework for Julia, inspired by the C++ Deep Learning framework Caffe.
   + New tutorial on [unsupervised pre-training with stacked denoising auto-encoders](http://mochajl.readthedocs.org/en/latest/tutorial/mnist-sDA.html).
   + An IJulia Notebook [demo of using pre-trained CNN on imagenet to do image classification](http://nbviewer.ipython.org/github/pluskid/Mocha.jl/blob/master/examples/ijulia/ilsvrc12/imagenet-classifier.ipynb).

## Neural Networks
+ [ANN.jl](https://github.com/EricChiang/ANN.jl) :: Artifical Neural Networks.
   + __Resources__
   + Blog post on [Neural networks and a dive into Julia](http://blog.yhathq.com/posts/julia-neural-networks.html)
+ [Boltzmann.jl](https://github.com/dfdx/Boltzmann.jl) :: Restricted Boltzmann Machines and Deep Belief Networks in Julia
+ [FANN.jl](https://github.com/gasagna/FANN.jl) :: A Julia wrapper for the Fast Artificial Neural Network Library (FANN).
+ [hinton.jl](https://github.com/lepisma/hinton.jl) :: Create hinton diagrams in Julia. Hinton diagrams are used to visualize weight matrices in neural networks.
+ [Julia_Neural_Network](https://github.com/nwenzel/Julia_Neural_Network) :: Basic Neural Network written in JuliaLang.
+ [KnetOnnx.jl](https://github.com/egeersu/KnetOnnx.jl) :: It reads an ONNX file and creates the corresponding Model in Knet that can be re-designed, re-trained or simply used for inference. 
+ [mlpnnets.jl](https://github.com/tautologico/learning/blob/master/nnets/mlp/julia/mlpnnets.jl) :: Feed-forward MLP neural network implementation.
+ [MultiLabelNeuralNetwork.jl](https://github.com/jperla/MultiLabelNeuralNetwork.jl) :: A simple feed-forward neural network for multi-label classification.
+ [neural.jl](https://github.com/compressed/neural.jl) :: is a Julia implementation of a neural network, based on Sergio Fierens Ruby version.
+ [NeuralNets.jl](https://github.com/anj1/NeuralNets.jl) :: Generic artificial neural networks in Julia.
+ [neuralnetwork.jl](https://github.com/tomaskrehlik/neuralnetwork.jl) :: is an implementation of label neural network originally written for MATLAB/Octave by Andrew Ng for Coursera Machine Learning Class.
+ [NeuralNetworks.jl](https://github.com/soumith/NeuralNetworks.jl) :: Various functions for Neural Networks implemented in Julia.
+ [ONNX.jl](https://github.com/FluxML/ONNX.jl) :: Read ONNX graphs and load these models in Julia.
+ [PyTorch.jl](https://github.com/zenna/PyTorch.jl):: PyTorch wrapper. 
+ [RecurrentNN.jl](https://github.com/Andy-P/RecurrentNN.jl) :: Deep RNN and LSTM in Julia.
+ [RNN.jl](https://github.com/kzahedi/RNN.jl) :: Recurrent Neural Networks.
+ [SimpleNets](https://github.com/rgehring/SimpleNets) :: Simple neural nets implementions in Julia.
+ [SpikeNet.jl](https://github.com/damiendr/SpikeNet.jl) :: A spiking neural network simulator written in Julia.
+ [StackedNets.jl](https://github.com/yarlett/StackedNets.jl) :: A simple interface to _deep_ stacks of neural network units that can be trained using gradient descent over defined error measures.
+ [SumProductNetworks.jl](https://github.com/trappmartin/SumProductNetworks.jl) :: Sum-Product Networks (deep probabilistic networks) package in Julia.

###### Resources
+ Blog post on '[Chess position evaluation with convolutional neural networks](http://int8.io/chess-position-evaluation-with-convolutional-neural-networks-in-julia/)' in Julia.



